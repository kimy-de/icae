## 1. Publication
> Jan Heiland and Yongho Kim (2022), *Convolutional Auto Encoders and Clustering for Low-dimensional Parametrization of Incompressible Flows*, 25th International Symposium on Mathematical Theory of Networks and Systems (MTNS)

## 2. Overview

* Traning session:  
    * `train.py` -> `centroids.py` -> `icae_train.py`
    * CAEs: 5 cases (reduced dimension [2,3,5,8,12]) 
    * k-means clustering: 15 cases (reduced dimension [2,3,5,8,12] x number of clusters [5,30,100])
    * iCAEs: 10 cases (reduced dimension [2,3,5,8,12] x number of clusters [5,30])
* Evaluation session:
    * Reconstruction errors: `evaluation.py` (POD, CAE, CAE100, iCAE5, iCAE30)
    * Approximation graphs: `trajectory.py` (POD, CAE, iCAE30)
    * 2-,3-dimensional $`\rho`$ distributions: `dist2d3d.py` (CAE)
* Directory information:
    * data: train data, test data, and POD-mode data
    * models: pretrained models and centroid data
    * results: result images
* Used libraries:
    * os, argparse, tqdm, time, matplotlib, numpy, sklearn, torch

* We provide everything including our pretrained models (pretrain.zip) and data. You can check the results without retraining after decompressing pretrain.zip in the "models" folder.

* If you want to compute everything from scratch (note that this may take several hours), use
```sh
source runitall.sh
```



## 3. Datasets

* Reynolds number: 40
* Train data: 400 snapshots in [0,10]
* Evaluation data: 800 snapshots in [0,10]
* Snapshot size $`n_v`$: 5922 (2x47x63)
* "0-10_800_47x63_re40.npy" and "0-10_800_47x63_re40.npy" are extracted from the json files generated by the FEM simulation used in
> Benner, Heiland, Bahmani (2022): *Convolutional Neural Networks for Very Low-dimensional LPV Approximations of Incompressible Navier-Stokes Equations* 

## 4. Training session

#### 4.1. CAEs

* batch_size: 64
* numer of epoch: 4000 
* latent variable dimension $`n_\rho`$: 2, 3, 5, 8, 12
* learning rate: 1e-3 (1e-4 if $`n_\rho=2`$)

```python
python train.py --latent_size 12 --num_epochs 3000 # --latent_size 3, 5, 8
```
```python
python train.py --latent_size 2 --num_epochs 4000  --lr 1e-4
```

#### 4.2. k-means clustering

```python
python centroids.py
```

#### 4.3. iCAEs

* number of epoch: 15000 
* latent variable dimension $`n_\rho`$: 2, 3, 5, 8, 12
* number of clusters $`k`$: 5, 30
* learning rate: 1e-3 

```python
python icae_train.py --latent_size 12 --num_clusters 5 # --latent_size 2, 3, 5, 8
```


## 5. Reproducibility of experimental results

* All the pretrained models and centroid data must be prepared.

#### 5.1. Reconstruction errors

```python
python evaluation.py
```
<div align="center">
<img src="/uploads/a0503daedc4c4a830f507ec86c89e439/recon_errors.png"  width="500" height="250">
</div>

#### 5.2. Sample trajectories

```python
python trajectory.py --latent_size 2 # 3, 5, 8, 12
```
<div align="center">
<img src="/uploads/29b95f04d484d6d5f3e46fdceecdc6e5/trajectory_2.png"  width="500" height="250">
</div>

#### 5.3. 2-,3-dimensional $`\rho`$ distributions
```python
python dist2d3d.py
```
<div align="center">
<img src="/uploads/d9a7c815c1870f973c7e4d1e94776d24/2d3d_result.png"  width="500" height="250">
</div>
